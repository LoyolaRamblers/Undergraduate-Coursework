---
title: "STAT 388 Project"
output: html_document
---
Tina Yang

Charles Hwang

Professor Matthews

STAT 388-001

10 December 2019

$(1)$ Introduction: We are building a model to predict the meter readings of energy usage in buildings in a series of given data sets. We are doing this as part of the [ASHRAE Great Energy Predictor III competition](kaggle.com/c/ashrae-energy-prediction) on Kaggle. There are four types of energy being used: chilled water, electric, hot water, and steam. The data consist of observations from over 1,000 buildings over a three-year timeframe. There are designated training and test data sets with the columns "building_id", energy type ("meter"), and "timestamp" containing $20,216,100$ and $41,697,600$ observations, respectively. There are also data sets containing weather information at the time of the meter reading for each (with columns like "air_temperature", "cloud_coverage", "dew_temperature", "sea_level_pressure", "wind_direction", and "wind_speed") and a "building_metadata" data set (with columns like "primary_use", "square_feet", "year_built", and "floor_count").

$(2)$ Methods: First, we read the data into RStudio (this took around 20 minutes due to the size of the files) and merged the appropriate data sets into the training or test data set using the join() function from the "dplyr" package. Then we looked at different variables and found that a logarithmic transformation on the "meter_reading" variable in the training data set would be appropriate. We built a classification and regression tree (CART) using the rpart() function from the "rpart" package and obtained its predicted values and cross-validation error. We pruned the tree with the prune() function but found no significant difference in predicted values. Finally, the predictions were copied to a newly-created data set "tpdf", untransformed, and written to a CSV file to be uploaded to the Kaggle competition webpage. All of the code for this project can be found in the $(5)$ Appendix of this report.

$(3)$ Results: The tree we fit had most of its splits on the "square_feet" and "meter" variables, with one on the "air_temperature" variable. The results can be found in the $(5.2)$ Tree subsection of this report. After uploading the CSV file to the Kaggle competition webpage, our calculated Kaggle score was $1.850$. The Kaggle score is calculated as the Root Mean Squared Logarithmic Error (RMSLE) of the model, which is given by $$\epsilon=\sqrt{\frac{1}{n}\sum_{i=1}^n (\ln(p_i+1)-\ln(a_i+1))^2}\:,$$ where $\epsilon$ is the RMSLE value (score), $n$ is the total number of observations in the (public/private) data set, $p_i$ is our prediction of target, and $a_i$ is the actual target for $i$. Because the score is based on the error of the model, a lower score indicates a model that is more well-fit to the data provided.

$(4)$ Conclusions/Future Work: We conclude that our Kaggle score was $1.850$. The Kaggle competition awards cash prizes to the teams with the five lowest Kaggle scores and (at the time of the creation of this report) had 4,071 competitors in total, many of which make numerous submissions over the course of the competition to improve upon their score and have several advanced resources and programs dedicated to prediction outside of R to use that we do not have. In light of this information, this score is good. There are many different things we would do in a similar project in the future if we had more time, including:
* Fitting a larger tree or multiple trees on the different factors of a variable ("meter", for example)
* Fitting a tree or trees with functions from different packages or a different set.seed() value
    + We experimented with fitting a series of trees using the tree() function from the "tree" package; however, the resulting Kaggle score of the model was greater than the one that resulted from the model in this report.
* Using different tree-based methods like [bagging](en.wikipedia.org/wiki/Bagging)
* Fitting a [random forest](en.wikipedia.org/wiki/Random_forest)
    + When attempting to fit a random forest, RStudio yielded an error stating "vector memory exhausted (limit reached?)". Thus, fitting a random forest on this data would likely require an adjustment to the memory settings of the computer that the code is being run on or running the code on a computer with more [RAM](en.wikipedia.org/wiki/RAM).
* Experimenting with other types of prediction models like gradient boosted models (GBMs) to see how the data would be handled

## (5) Appendix
### (5.1) Data Cleaning

```{r Data Cleaning, message=FALSE, warning=FALSE}
rm(list=ls())
building_metadata <- read.csv(file="/Users/newuser/Desktop/Notes/STAT 388/ashrae-energy-prediction/building_metadata.csv",header=TRUE)
sample_submission <- read.csv(file="/Users/newuser/Desktop/Notes/STAT 388/ashrae-energy-prediction/sample_submission.csv",header=TRUE)
test <- read.csv(file="/Users/newuser/Desktop/Notes/STAT 388/ashrae-energy-prediction/test.csv",header=TRUE)
train <- read.csv(file="/Users/newuser/Desktop/Notes/STAT 388/ashrae-energy-prediction/train.csv",header=TRUE)
weather_test <- read.csv(file="/Users/newuser/Desktop/Notes/STAT 388/ashrae-energy-prediction/weather_test.csv",header=TRUE)
weather_train <- read.csv(file="/Users/newuser/Desktop/Notes/STAT 388/ashrae-energy-prediction/weather_train.csv",header=TRUE)
library(car)
library(dplyr)
library(rpart)
train <- left_join(train,building_metadata,by="building_id")
train <- left_join(train,weather_train,by=c("site_id","timestamp"))
test <- left_join(test,building_metadata,by="building_id")
test <- left_join(test,weather_test,by=c("site_id","timestamp"))
summary(train$meter_reading)
hist(train$meter_reading)
summary(log(train$meter_reading+1)) # Looking at summary of possible logarithmic transformation
hist(log(train$meter_reading+1)) # Performing a logarithmic transformation on meter reading
train$meter_reading <- log(train$meter_reading+1) # Done
train$timestamp <- as.integer(train$timestamp)
test$timestamp <- as.integer(test$timestamp)
```

### (5.2) Tree

```{r Tree}
set.seed(1012)
tree <- rpart(meter_reading~.,data=train)
printcp(tree)
plotcp(tree)
plot(tree,uniform=TRUE,main="Regression Tree")
text(tree,use.n=TRUE,all=TRUE,cex=.7)
summary(tree)
ptree <- prune(tree,cp=tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"])
plot(ptree,uniform=TRUE,main="Pruned Regression Tree")
text(ptree,use.n=TRUE,all=TRUE,cex=.7)
cat("Cross validation error:",min(tree$cptable[,"xerror"]))
```

### (5.3) Predictions

The output in this subsection is suppressed because RStudio would not allow it to be knit. Similarly to when we attempted to fit a random forest, as discussed in the fourth bullet point of $(4)$ Conclusions/Future Work, RStudio yielded an error stating "vector memory exhausted (limit reached?)" when this subsection was in the process of being knitted. However, the code will still run without any errors.

```{r Predictions, eval=FALSE}
treepred <- predict(tree,test)
table(treepred)
tpdf <- as.data.frame(rep(0,length(treepred))) # Exporting predictions to CSV file for Kaggle submission
tpdf$row_id <- test$row_id
tpdf$meter_reading <- exp(treepred) # Untransforming predictions
tpdf$`rep(0, length(treepred))` <- NULL
write.csv(as.data.frame(tpdf),"STAT 388 Project Submission.csv",row.names=FALSE)
```

### (5.4) Score

```{r Score}
# Kaggle score: 1.850 (88.87%)
1.850 < 2.250
```

This score, as previously discussed in $(4)$ Conclusions/Future Work, is relatively good, given the resources that other competitors have and the shorter time period we had to complete this project.