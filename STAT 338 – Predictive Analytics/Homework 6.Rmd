---
title: "STAT 388"
output: html_document
---
Charles Hwang

Professor Matthews

STAT 388-001

22 November 2019

## Problem 1

```{r Problem 1}
rm(list=ls())
# Boosting and bagging are similar because they both use the same process of bootstrapping on the data set. Boosting and bagging are different because boosting uses a sequential process and is slower while bagging has potential for overfitting but is easier to interpret than boosting.
```

## Problem 2

```{r Problem 2,message=FALSE}
library(gbm)
data <- read.csv(file="/Users/newuser/Desktop/HW6.csv")
names(data)[1] <- "ID"
gbm <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.01,cv.folds=10)
summary(gbm)
gbm01 <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.001,cv.folds=10)
gbm05 <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.005,cv.folds=10)
gbm15 <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.015,cv.folds=10)
gbm2 <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.02,cv.folds=10)
gbm25 <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.025,cv.folds=10)
gbm3 <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.03,cv.folds=10)
gbm35 <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.035,cv.folds=10)
gbm4 <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.04,cv.folds=10)
gbm45 <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.045,cv.folds=10)
gbm5 <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.05,cv.folds=10)
gbm1 <- gbm(Y~.,distribution="gaussian",data=data,shrinkage=.1,cv.folds=10)
plot(c(.001,.005,.01,.015,.02,.025,.03,.035,.04,.045,.05,.1),c(sum(data$Y-predict(gbm01,n.trees=100))^2,sum(data$Y-predict(gbm05,n.trees=100))^2,sum(data$Y-predict(gbm,n.trees=100))^2,sum(data$Y-predict(gbm15,n.trees=100))^2,sum(data$Y-predict(gbm2,n.trees=100))^2,sum(data$Y-predict(gbm25,n.trees=100))^2,sum(data$Y-predict(gbm3,n.trees=100))^2,sum(data$Y-predict(gbm35,n.trees=100))^2,sum(data$Y-predict(gbm4,n.trees=100))^2,sum(data$Y-predict(gbm45,n.trees=100))^2,sum(data$Y-predict(gbm5,n.trees=100))^2,sum(data$Y-predict(gbm1,n.trees=100))^2),type="o",xlab="Î»",ylab="Mean Squared Error")
```