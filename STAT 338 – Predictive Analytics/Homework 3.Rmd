---
title: "STAT 388"
output: html_document
---
Charles Hwang

Professor Matthews

STAT 388-001

4 October 2019

## Exercise 6.4

```{r Exercise 6.4}
rm(list=ls())
# a) iv. — As s increases, the βj's will increase until reaching the least squares estimate, decreasing the training RSS.
# b) ii. — As s increases, the βj's will increase until reaching the least squares estimate, initially decreasing the test RSS. The test RSS will increase when there are too many variables and overfitting occurrs.
# c) iii. — As s increases, the βj's will increase until reaching the least squares estimate, increasing the variance.
# d) iv. — As s increases, the βj's will increase until reaching the least squares estimate, decreasing the bias according to the bias-variance tradeoff.
# e) v. — By definition, irreducible error is inherent due to the nature of the model and thus independent from s.
```

## Exercise 6.9 (nice!)

```{r Exercise 6.9 (nice!)}
rm(list=ls())
library(ISLR)
library(glmnet)
set.seed(69)                                                  # Exercise 6.9a
n <- floor(0.75*nrow(College))
trains <- sample(seq_len(nrow(College)),size=n)
trainvec <- College[trains,]
testvec <- College[-trains,]
lm <- lm(Apps~.,data=trainvec)                                # Exercise 6.9b
summary(lm)
lmerr <- mean((predict(lm,testvec)-testvec$Apps)^2)
lmerr
trainmat <- model.matrix(Apps~.,data=trainvec)                # Exercise 6.9c
testmat <- model.matrix(Apps~.,data=testvec)
grid <- 10^seq(10,-2,length=100)
ridge <- glmnet(trainmat,trainvec$Apps,alpha=0,lambda=grid)
cvridge <- cv.glmnet(trainmat,trainvec$Apps,alpha=0,lambda=grid)
bestλridge <- cvridge$lambda.min
ridgeerr <- mean((predict(ridge,s=bestλridge,newx=testmat)-testvec$Apps)^2)
c(bestλridge,ridgeerr)
lasso <- glmnet(trainmat,trainvec$Apps,alpha=1,lambda=grid)   # Exercise 6.9d
cvlasso <- cv.glmnet(trainmat,trainvec$Apps,alpha=1,lambda=grid)
bestλlasso <- cvlasso$lambda.min
lassoerr <- mean((predict(lasso,s=bestλlasso,newx=testmat)-testvec$Apps)^2)
c(bestλlasso,lassoerr)
predict(lasso,s=bestλlasso,type="coefficients")
# There are 10 nonzero coefficients.
library(pls)                                                  # Exercise 6.9e
pcr <- pcr(Apps~.,data=trainvec,scale=TRUE,validation="CV")
summary(pcr) # Lowest value is at M = 17
pcrerr <- mean((predict(pcr,testvec,ncomp=17)-testvec$Apps)^2)
c(pcrerr,17)
plsr <- plsr(Apps~.,data=trainvec,scale=TRUE,validation="CV") # Exercise 6.9f
summary(plsr) # Lowest value is at M = 9
plsrerr <- mean((predict(plsr,testvec,ncomp=9)-testvec$Apps)^2)
c(plsrerr,9)
testavg <- mean(testvec$Apps)                                 # Exercise 6.9g
lmcorr <- 1-lmerr/mean((testavg-testvec$Apps)^2)
ridgecorr <- 1-ridgeerr/mean((testavg-testvec$Apps)^2)
lassocorr <- 1-lassoerr/mean((testavg-testvec$Apps)^2)
pcrcorr <- 1-pcrerr/mean((testavg-testvec$Apps)^2)
plsrcorr <- 1-plsrerr/mean((testavg-testvec$Apps)^2)
c(lmcorr,ridgecorr,lassocorr,pcrcorr,plsrcorr)
# The r^2 for all models are very similar. We can predict the number of college applications received quite accurately. There is not much difference among the test errors between the models.
```

## Exercise 6.10

```{r Exercise 6.10}
rm(list=ls())
set.seed(1)
x <- matrix(rnorm(1000*20),1000,20)          # Exercise 6.10a
β <- rnorm(20)
β[2] <- 0
β[3] <- 0
β[5] <- 0
β[7] <- 0
β[11] <- 0
β[13] <- 0
β[17] <- 0
error <- rnorm(1000)
y <- x%*%β+error
train <- sample(seq(1000),100,replace=FALSE) # Exercise 6.10b
test <- (-train)
xtrain<-x[train,]
xtest<-x[test,]
ytrain<-y[train]
ytest<-y[test]
library(leaps)                               # Exercise 6.10c
data.train <- data.frame(y=ytrain,x=xtrain)

                                             # Exercise 6.10d

                                             # Exercise 6.10e

                                             # Exercise 6.10f

                                             # Exercise 6.10g
```