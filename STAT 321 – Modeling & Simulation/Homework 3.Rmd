---
title: "STAT 321"
output: html_document
---
Charles Hwang

Professor Matthews

STAT 321-001

4 October 2019

## Exercise 9.4

```{r Exercise 9.4}
rm(list=ls())
# "Truncating to n terms, the error is no greater in magnitude than the last term in the sum."
x <- 1.5-1
l <- log(1+x)
c(x^46/46,x^47/47,10^-16,x^48/48,x^49/49)
# There are 48 terms required to calculate log(1.5) with an error of 10^-16 or less.
x <- 2-1
c(x^9999999999999999/9999999999999999,10^-16,x^10000000000000000/10000000000000000) # (1)^10000000000000000/10000000000000000 = 1/10000000000000000 ≤ 10^-16
# There are 10,000,000,000,000,000 terms requried to calculate log(2) with an error of 10^-16 or less.
x <- sqrt(2)-1
c(x^36/36,x^37/37,10^-16,x^38/38,x^39/39)
# By calculating log(sqrt(2)) then multiplying by 2, it significantly reduces the number of terms needed to calculate with an error of 10^-16 or less.
```

## Exercise 9.5

```{r Exercise 9.5}
rm(list=ls())
# First formula:                            Second forumla:
# Σ(xi-xbar)^2/(n-1) =
# Σ(xi^2-2*xi*xbar+xbar^2)/(n-1) =
# (Σ(xi^2-2*xi*xbar)+n*xbar^2)/(n-1) =
# (Σ(xi^2)-2*xbar*Σ(xi)+n*xbar^2)/(n-1) =
# (Σ(xi^2)-2*xbar(n*xbar)+n*xbar^2)/(n-1) =
# (Σ(xi^2)-2*n*xbar^2+n*xbar^2)/(n-1) =
# (Σ(xi^2)-n*xbar^2)/(n-1) =                (Σ(xi^2)-n*xbar^2)/(n-1) =
# ... =                                     ... =
# σ^2/(n-1) =                               σ^2/(n-1) =
# S^2                                       S^2
# The first formula takes six operations to get to the same point that the second formula begins at.
# The second formula suffers from catastrophic cancellation because the xi's (and xbar) may have a different number of decimal places. When summed together this causes catastrophic cancellation.
x <- c(.123456789,.123456789123456789) # Choosing two numbers with different decimal lengths
n <- length(x)
xbar <- mean(x)
f1 <- sum((x[1]-xbar)^2,(x[n]-xbar)^2)
f2 <- sum(x[1]^2,x[n]^2)-n*xbar^2
c(f1,f2)
# There is a clear difference in the answers for the case where n = 2 due to catastrophic cancellation in the second formula, resulting in a decrease in significant digits.
```

## Exercise 9.9

```{r Exercise 9.9}
rm(list=ls())
x <- c(11,12,13,14,15,16,17,18,19,20)
y <- c(21,22,23,24,25,26,27,28,29,30)
z <- rep(0,length(x)+length(y))
sum <- z
n <- mean(length(x),length(y))
for(k in 1:2*n){
  i <- 1
  base <- x[1]*y[k+1]
  while(i < k){
    sum[i] <- x[i]*y[k-i]
    i <- i+1
  }
  z[k] <- base+sum(sum)
}
z
# z <- c(x[1]y[1],x[1]y[2]+x[2]y[1],x[1]y[3]+x[2]y[2]+x[3]y[1],...,x[1]y[n]+x[2]y[n-1]+...+x[n]y[1],x[2]y[n]+x[3]y[n-1]+...+x[n]y[2],x[3]y[n]+x[4]y[n-1]+...+x[n]y[3],...,x[n]y[n])
# z[1] <- x[1]y[1]
# z[2] <- x[1]y[2]+x[2]y[1]
# z[3] <- x[1]y[3]+x[2]y[2]+x[3]y[1]
# z[...]
# z[n] <- x[1]y[n]+x[2]y[n-1]+...+x[n]y[1]
# z[n+1] <- x[2]y[n]+x[3]y[n-1]+...+x[n]y[2]
# z[n+2] <- x[3]y[n]+x[4]y[n-1]+...+x[n]y[3]
# z[...]
# z[2n-1] <- x[n]y[n]
# z[2n] <- -(x[n]y[n+1]+x[n+1]y[n])
```

## Exercise 9.10

```{r Exercise 9.10}
rm(list=ls())
i <- 1 # Addition
add <- rep(0,1000)
while(i <= 1000) {
rand <- rnorm(2)
add[i] <- system.time(sum(rand))[3]
i = i+1
}
i <- 1 # Multiplication
times <- rep(0,1000)
while(i <= 1000) {
rand <- rnorm(2)
times[i] <- system.time(prod(rand))[3]
i = i+1
}
i <- 1 # Exponential
exp <- rep(0,1000)
while(i <= 1000) {
rand <- rnorm(1)
exp[i] <- system.time(exp(rand))[3]
i = i+1
}
i <- 1 # Sinusoidal
sine <- rep(0,1000)
while(i <= 1000) {
rand <- rnorm(1)
sine[i] <- system.time(sin(rand))[3]
i = i+1
}
par(mfrow=c(2,2))
hist(add)
hist(times)
hist(exp)
hist(sine)
# The distributions are all nearly identical with one another. As expected, the time it takes to run each function is minimal, with a few outlier runs taking longer than usual.
```

## Exercise 10.3

```{r Exercise 10.3}
rm(list=ls())
library(spuRs)
fixedpoint(cos,0)
cosx <- function(x){
  c(cos(x)-x,-sin(x)-1)
}
newtonraphson(cosx,0)
# Yes, the Newton—Raphson method is faster than the fixed-point method.
```

## Exercise 10.10a

```{r Exercise 10.10a}
rm(list=ls())
library(spuRs)
sine <- function(x){
  c(sin(x),cos(x))
}
nr <- newtonraphson(sine,3)
cat("The Newton—Raphson method was able to get within",abs(nr-pi),"of π.")
```

## Exercise 10.10b

```{r Exercise 10.10b}
rm(list=ls())
estpi <- function(x = 3,n = 7){
  f <- rep(0,n)
  i <- 0
  while(i <= n) {
    f[i+1] <- (-1)^i*(x^(2*i+1))/factorial(2*i+1) # f[i+1] defined to avoid calling f[0]
    i <- i+1
  }
  print(x+sum(f))
  plot(f) # Plot is from 1 to 8, corresponding to the entries in f
}
estpi()
```

## Exercise 10.10c

```{r Exercise 10.10c}
rm(list=ls())
estpi <- function(x = 3,n = 7){
  f <- rep(0,n)
  i <- 0
  while(i <= n) {
    f[i+1] <- (-1)^i*(x^(2*i+1))/factorial(2*i+1) # f[i+1] defined to avoid calling f[0]
    i <- i+1
  }
  print(c(f[n+1],10^-6)) # Prints last term of f (which is the smallest)
}
estpi()
estpi(n=8) # Testing values of n, increasing by 1
# An approximation correct up to six decimal places is obtained when n >= 8.
# A better way to calculate pi would be to copy and paste the number of digits of pi desired from an online webpage containing such information (piday.org/million) or to invoke the pi constant built into R:
pi
```